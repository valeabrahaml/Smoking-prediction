{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the __experimental notebook__, here we'll demonstrate many of the things we tried but didn't get into the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost \n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from ydata_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv('train.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess: checking missing values, and seeing the datatypes. In order to see if the data has categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "any(data.dtypes == 'object') #no strings- all numeric\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After seeing that the data is all numerical we're going to check if there are missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().any() #no missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to head the data to get a sense of what are the values like and get a more visual feel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After performing EDA found on the deliverable notebook we started doing Feature engineering. \n",
    "The following features were created after investigating in Mayo Clinic's website of what we could calculate with the available data: \n",
    "* BMI (Body Mass Index): is a measure of body fat based on height and weight that applies to adult men and women.\n",
    "* Average eyesight: used to minimize the number of columns in order to simplify the model\n",
    "* Average hearing: used to minimize the number of columns in order to simplify the model\n",
    "* Cholesterol ratio non-HDL: for predicting your risk of heart disease, many healthcare professionals now believe that determining your non-HDL cholesterol level may be more useful than calculating your cholesterol ratio.\n",
    "* Total cholesterol: this is the total amount of cholesterol that’s circulating in your blood. Here’s the formula for calculating it: HDL + LDL + 20% triglycerides = total cholesterol.\n",
    "* Triglyceride-to-HDL: it can help determine a person's risk of heart disease triglycerides/HDL level.\n",
    "* Liver Enzyme Ratio: Liver function tests check the levels of certain enzymes and proteins in your blood. Levels that are higher or lower than usual can mean liver problems. \n",
    "* Creatinine clearance: A creatinine test is a measure of how well your kidneys are performing their job of filtering waste from your blood.\n",
    "* Systolic to relaxation ratio: Systolic pressure is affected by a variety of factors. Factors such as anxiety, caffeine consumption, and performing resistance and cardiovascular exercises, cause immediate, temporary increases in systolic pressure.\n",
    "\n",
    "We also tried thougt that categorizeing/bining would help the model by having less numerical features, adding categorical with One Hot Encoding.\n",
    "After trying this aproach we found that the models where more precise without cagetorizing, so we went back to purely numerical.\n",
    "Then we found that many of the newly created features were doing the opposite of improving the model's performance. We tried many combinations and tested the feaures importance but found little of it. That's why we decided to simply the model as seen on the deliverable notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate BMI\n",
    "data['BMI'] = data['weight(kg)'] / ((data['height(cm)'] / 100) ** 2)\n",
    "\n",
    "# Categorize BMI\n",
    "data['BMI_category'] = data['BMI'].apply(lambda x: 'Underweight' if x < 18.5 else \n",
    "                                         ('Normal weight' if x < 25 else \n",
    "                                          ('Overweight' if x < 30 else 'Obesity')))\n",
    "\n",
    "# Calculate average eyesight\n",
    "data['avg eyesight'] = (data['eyesight(left)'] + data['eyesight(right)']) / 2\n",
    "\n",
    "# Categorize average eyesight\n",
    "data['eyesight_category'] = data['avg eyesight'].apply(lambda x: 'Good' if x > 0.8 else \n",
    "                                                       ('Moderate' if x > 0.4 else 'Poor'))\n",
    "# Calculate Cholesterol ratio HDL\n",
    "data['Cholesterol ratio HDL'] = (data['HDL'] + data['LDL']) / data['HDL']\n",
    "\n",
    "\n",
    "# Categorize Cholesterol ratio HDL (using arbitrary thresholds)\n",
    "data['Cholesterol_ratio_category'] = data['Cholesterol ratio HDL'].apply(lambda x: 'Low' if x < 3.5 else \n",
    "                                                                         ('Normal' if x <= 5 else 'High'))\n",
    "\n",
    "# Calculate Total cholesterol\n",
    "data['Total cholesterol'] = data['HDL'] + data['LDL'] + (data['triglyceride'] / 0.2)\n",
    "\n",
    "# Categorize Total Cholesterol\n",
    "data['Total_cholesterol_category'] = data['Total cholesterol'].apply(\n",
    "    lambda x: 'Desirable' if x < 200 else ('Borderline high' if x <= 239 else 'High'))\n",
    "\n",
    "# Calculate Triglyceride-to-HDL ratio\n",
    "data['Triglyceride-to-HDL'] = data['triglyceride'] / data['HDL']\n",
    "\n",
    "# Categorize Triglyceride-to-HDL ratio\n",
    "data['Triglyceride_to_HDL_category'] = data['Triglyceride-to-HDL'].apply(\n",
    "    lambda x: 'Optimal' if x < 2 else ('Moderate' if x <= 4 else 'High'))\n",
    "\n",
    "\n",
    "data[\"Liver Enzyme Ratio\"] = data[\"AST\"] / data[\"ALT\"]\n",
    "\n",
    "# Categorize Liver Enzyme Ratio\n",
    "data['Liver_Enzyme_Ratio_category'] = data['Liver Enzyme Ratio'].apply(\n",
    "    lambda x: 'Low' if x < 0.8 else ('Normal' if x <= 1.2 else 'High'))\n",
    "\n",
    "#creatine clearance (kidney function)\n",
    "data['creatinine clearance']= (140- (data['age']* data['weight(kg)'])/(72* data['serum creatinine']))\n",
    "\n",
    "# Categorize Creatinine Clearance\n",
    "data['Creatinine_Clearance_category'] = data['creatinine clearance'].apply(\n",
    "    lambda x: 'Normal' if x > 90 else \n",
    "              ('Mildly Decreased' if x > 60 else \n",
    "               ('Moderately to Severely Decreased' if x > 30 else \n",
    "                ('Severely Decreased' if x > 15 else 'Kidney Failure'))))\n",
    "                # Create 'age_group' column directly\n",
    "data['age_group'] = data['age'].apply(lambda x: 'Young Adult' if x <= 35 else ('Middle-Aged Adult' if x <= 55 else 'Senior Adult'))\n",
    "\n",
    "# Create 'systolic_to_relaxation_ratio' column as the ratio of systolic to relaxation (diastolic) blood pressure\n",
    "data['systolic_to_relaxation_ratio'] = data['systolic'] / data['relaxation']\n",
    "\n",
    "# Categorize the ratio\n",
    "data['ratio_category'] = data['systolic_to_relaxation_ratio'].apply(\n",
    "    lambda x: 'Low' if x < 1.0 else ('Normal' if x <= 1.5 else 'High'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we procedeed to test multiple combinations of features categorized and uncategorized with a sample of 10% to make the testing faster with the following models.\n",
    "* Logistic regression: Used for binary classification problems (yes/no, true/false). It can be extended to multiclass classification via techniques like one-vs-rest (OvR).\n",
    "* Random Forest: Suitable for both classification and regression tasks. Good for complex datasets with high dimensionality and feature interactions.\n",
    "* XGBoost: Can be used for classification, regression, ranking, and user-defined prediction tasks. \n",
    "\n",
    "Compared to other models such as Random Forest and Logistic Regression, XGBoost demonstrated superior performance in our scenario. Random Forest, builds multiple decision trees too but it combines their predictions to improve accuracy. While Random Forest is robust and less prone to overfitting than XGBoost, it may not capture complex relationships as effectively. \n",
    "\n",
    "Logistic Regression, on the other hand, is a linear model that models the probability of a binary outcome using a logistic function. Although Logistic Regression is simple and interpretable, it may struggle to capture non-linear relationships present in the data.\n",
    "\n",
    "The reason XGBoost performed better in our case is primarily due to its ability to handle complex non-linear relationships and interactions between features. This capability allowed XGBoost to effectively learn from the dataset and make accurate predictions regarding smoking behavior. \n",
    "\n",
    "While Random Forest and Logistic Regression are viable alternatives, they may not capture the nuances present in the data as comprehensively as XGBoost. Ultimately, the choice of model depends on the specific characteristics of the dataset and the goals of the analysis.\n",
    "\n",
    "Splitting data x and y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Dealing with outliers__\n",
    "\n",
    "Our first attempt was to eliminate all of the outliers as seen below, after debating the reasons we found that some categories didn´t make sense to remove outilers, for example: Age, weight, hearing and eyesight to name a few. After trying that we saw a drop on the model's performance, which is why we only eliminated outliers in the columns: ALT, LDL, triglyceride, AST, Gtp.\n",
    "\n",
    "The first attempt to remove \"outliers\" in every column is shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train= pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: Lower Bound = -278696.25, Upper Bound = 437951.25\n",
      "age: Lower Bound = -20.0, Upper Bound = 115.0\n",
      "height(cm): Lower Bound = 120.0, Upper Bound = 210.0\n",
      "weight(kg): Lower Bound = 0.0, Upper Bound = 135.0\n",
      "waist(cm): Lower Bound = 29.0, Upper Bound = 137.0\n",
      "eyesight(left): Lower Bound = -0.7999999999999996, Upper Bound = 2.8\n",
      "eyesight(right): Lower Bound = -0.7999999999999996, Upper Bound = 2.8\n",
      "hearing(left): Lower Bound = 1.0, Upper Bound = 1.0\n",
      "hearing(right): Lower Bound = 1.0, Upper Bound = 1.0\n",
      "systolic: Lower Bound = 50.0, Upper Bound = 194.0\n",
      "relaxation: Lower Bound = 22.0, Upper Bound = 130.0\n",
      "fasting blood sugar: Lower Bound = 38.0, Upper Bound = 155.0\n",
      "Cholesterol: Lower Bound = 7.0, Upper Bound = 385.0\n",
      "triglyceride: Lower Bound = -275.0, Upper Bound = 517.0\n",
      "HDL: Lower Bound = -31.0, Upper Bound = 140.0\n",
      "LDL: Lower Bound = -57.0, Upper Bound = 285.0\n",
      "hemoglobin: Lower Bound = 5.800000000000001, Upper Bound = 23.8\n",
      "Urine protein: Lower Bound = 1.0, Upper Bound = 1.0\n",
      "serum creatinine: Lower Bound = 2.220446049250313e-16, Upper Bound = 1.7999999999999998\n",
      "AST: Lower Bound = -16.0, Upper Bound = 65.0\n",
      "ALT: Lower Bound = -48.0, Upper Bound = 96.0\n",
      "Gtp: Lower Bound = -86.0, Upper Bound = 148.0\n",
      "dental caries: Lower Bound = 0.0, Upper Bound = 0.0\n",
      "smoking: Lower Bound = -4.0, Upper Bound = 5.0\n",
      "Rows removed: 45998\n"
     ]
    }
   ],
   "source": [
    "# Keep a count of the original number of rows\n",
    "original_row_count = len(df_train)\n",
    "\n",
    "# Initialize a mask to keep track of rows to keep\n",
    "mask = pd.Series(True, index=df_train.index)\n",
    "\n",
    "# Loop through each column to update the mask for outliers\n",
    "for column in df_train.columns:\n",
    "    Q1 = df_train[column].quantile(0.25)\n",
    "    Q3 = df_train[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Define the bounds for outliers\n",
    "    lower_bound = Q1 - 4 * IQR\n",
    "    upper_bound = Q3 + 4 * IQR\n",
    "\n",
    "    # Print the limits\n",
    "    print(f\"{column}: Lower Bound = {lower_bound}, Upper Bound = {upper_bound}\")\n",
    "\n",
    "    # Update the mask to false for rows that are outliers in the current column\n",
    "    mask = mask & (df_train[column] >= lower_bound) & (df_train[column] <= upper_bound)\n",
    "\n",
    "# Apply the mask to filter out outliers across all columns\n",
    "df_train_filtered = df_train[mask]\n",
    "\n",
    "# Calculate the number of rows after filtering\n",
    "filtered_row_count = len(df_train_filtered)\n",
    "\n",
    "# Calculate and print the number of rows removed\n",
    "rows_removed = original_row_count - filtered_row_count\n",
    "print(f\"Rows removed: {rows_removed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= data.sample(frac=.1)\n",
    "X_train=data.drop(columns=['id','smoking'])\n",
    "y_train=data['smoking']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell was used to test __Logistic Regression__ , __Random Forest__, __XGBoost__.\n",
    "\n",
    "We chose logistic regression because of it's ability to predict. It works fast on any size data, and you can easily understand what's going on. Plus, you can tweak it to avoid making too sure of itself, keeping predictions realistic. Simple, quick, and smart.\n",
    "\n",
    "Random Forest is great for binary predictions with numerical data. It uses many decision trees to boost accuracy and tackle overfitting, giving you a more reliable model. It's good at uncovering complex patterns logistic regression might miss and ranks variables by their importance, offering deep insights. While it's a bit heavier on computation and less straightforward to interpret than simpler models, its power in handling diverse data sizes and complexity makes it a more robust choice. \n",
    "\n",
    "And finlally XGBoost shines in binary prediction with its precision and speed, perfect for numerical data. It builds on gradient boosting by correcting previous mistakes, leading to highly accurate models. It's fast, thanks to optimized algorithms that work well on big data, and it's smart at avoiding overfitting with its regularized learning approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'XGBOOST': xgboost.XGBClassifier()}\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "import numpy as np\n",
    "\n",
    "# Assuming models is a dictionary of model names and their corresponding initialized objects\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training and evaluating {model_name} model\")\n",
    "    \n",
    "    # Create a pipeline for scaling and model training\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    # Use roc_auc_score as the scoring metric\n",
    "    auc_scorer = make_scorer(roc_auc_score, needs_proba=True, multi_class='ovo')\n",
    "\n",
    "    # Calculate cross-validation AUC-ROC scores\n",
    "    auc_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring=auc_scorer)\n",
    "\n",
    "    # Calculate and print average performance across folds\n",
    "    avg_auc = np.mean(auc_scores)\n",
    "    print(f'Average {model_name} AUC-ROC = {avg_auc}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to try ___Random Forest__ due to it's scalability and because it is less prone to overfitting than XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import xgboost\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train= pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALT: Lower Bound = -48.0, Upper Bound = 96.0\n",
      "LDL: Lower Bound = -57.0, Upper Bound = 285.0\n",
      "triglyceride: Lower Bound = -275.0, Upper Bound = 517.0\n",
      "AST: Lower Bound = -16.0, Upper Bound = 65.0\n",
      "Gtp: Lower Bound = -86.0, Upper Bound = 148.0\n",
      "Rows removed: 2807\n"
     ]
    }
   ],
   "source": [
    "# Keep a count of the original number of rows\n",
    "original_row_count2 = len(train)\n",
    "\n",
    "# Columns you want to check for outliers\n",
    "columns_to_check = ['ALT', 'LDL', 'triglyceride', 'AST', 'Gtp']\n",
    "\n",
    "# Initialize a mask to keep track of rows to keep\n",
    "mask = pd.Series(True, index=train.index)\n",
    "\n",
    "# Loop through each column to update the mask for outliers\n",
    "for column in columns_to_check:\n",
    "    Q1 = train[column].quantile(0.25)\n",
    "    Q3 = train[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Define the bounds for outliers\n",
    "    lower_bound = Q1 - 4 * IQR\n",
    "    upper_bound = Q3 + 4 * IQR\n",
    "\n",
    "    # Print the limits\n",
    "    print(f\"{column}: Lower Bound = {lower_bound}, Upper Bound = {upper_bound}\")\n",
    "\n",
    "    # Update the mask to false for rows that are outliers in the current column\n",
    "    mask = mask & (train[column] >= lower_bound) & (train[column] <= upper_bound)\n",
    "\n",
    "# Apply the mask to filter out outliers across all columns\n",
    "train_filtered = train[mask]\n",
    "\n",
    "# Calculate the number of rows after filtering\n",
    "filtered_row_count = len(train_filtered)\n",
    "\n",
    "# Calculate and print the number of rows removed\n",
    "rows_removed = original_row_count - filtered_row_count\n",
    "print(f\"Rows removed: {rows_removed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159256"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_row_count2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_filtered=train_filtered.drop(columns=['hearing(left)','hearing(right)','Urine protein'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= train_filtered['smoking']\n",
    "X= train_filtered.drop(columns='smoking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "# Define parameter grid\n",
    "param_dist = {\n",
    "    \"n_estimators\": randint(10, 1000),\n",
    "    \"max_features\": ['auto', 'sqrt','log2'],\n",
    "    \"max_depth\": randint(2,30),\n",
    "    \"min_samples_split\": randint(2, 20),\n",
    "    \"min_samples_leaf\": randint(1, 20),\n",
    "    \"bootstrap\": [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_dist = {\n",
    "    'n_estimators': randint(10, 1000),  # Using a distribution for 'n_estimators'\n",
    "    'max_depth': randint(1, 20),\n",
    "    'min_samples_split': randint(2, 20),\n",
    "    'min_samples_leaf': randint(1, 20),\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Instantiate Random Forest classifier\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Define a custom scorer using roc_auc_score\n",
    "auc_scorer = make_scorer(roc_auc_score, greater_is_better=True)\n",
    "\n",
    "# Randomized search with custom scoring\n",
    "random_search = RandomizedSearchCV(rf, param_distributions=param_dist, n_iter=25, cv=5, verbose=2, random_state=42, n_jobs=-1, scoring=auc_scorer)\n",
    "\n",
    "# Fit the random search model\n",
    "random_search.fit(X, y)\n",
    "\n",
    "# Best parameters found\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = {\n",
    "    'n_estimators': 334,  # Using a distribution for 'n_estimators'\n",
    "    'max_depth': 12,\n",
    "    'min_samples_split': 9,\n",
    "    'min_samples_leaf':11,\n",
    "    'bootstrap': True\n",
    "}\n",
    "rf = RandomForestClassifier(**best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X)\n",
    "y_pred_proba = rf.predict_proba(X)[:, 1]\n",
    "auc_score = roc_auc_score(y, y_pred_proba)\n",
    "\n",
    "print(f\"AUC Score: {auc_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After learning __SVM__ in class we decided to try it.\n",
    "\n",
    "SVM is ideal for binary prediction, excelling with numerical data. It focuses on creating the best boundary between classes, ensuring high accuracy and minimal overfitting. With different kernels, SVM can tackle both linear and non-linear data, offering great flexibility. Although it might require more computational power for large datasets, its precision makes it a top choice for data science students looking to master a reliable and adaptable classification tool.\n",
    "\n",
    "The following attempt was done as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train= pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALT: Lower Bound = -48.0, Upper Bound = 96.0\n",
      "LDL: Lower Bound = -57.0, Upper Bound = 285.0\n",
      "triglyceride: Lower Bound = -275.0, Upper Bound = 517.0\n",
      "AST: Lower Bound = -16.0, Upper Bound = 65.0\n",
      "Gtp: Lower Bound = -86.0, Upper Bound = 148.0\n",
      "Rows removed: 2807\n"
     ]
    }
   ],
   "source": [
    "# Keep a count of the original number of rows\n",
    "original_row_count = len(df_train)\n",
    "# After analyzing the graphs and experimenting we determied that the following columns have extreme outliers affecting the model performace\n",
    "columns = ['ALT', 'LDL', 'triglyceride', 'AST', 'Gtp']\n",
    "\n",
    "# Initialize a mask to keep track of rows to keep\n",
    "mask = pd.Series(True, index=df_train.index)\n",
    "\n",
    "# Loop through each column to update the mask for outliers\n",
    "for column in columns:\n",
    "    Q1 = df_train[column].quantile(0.25)\n",
    "    Q3 = df_train[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Define the bounds for outliers\n",
    "    lower_bound = Q1 - 4 * IQR\n",
    "    upper_bound = Q3 + 4 * IQR\n",
    "\n",
    "    print(f\"{column}: Lower Bound = {lower_bound}, Upper Bound = {upper_bound}\")\n",
    "\n",
    "    # Update the mask to false for rows that are outliers in the current column\n",
    "    mask = mask & (df_train[column] >= lower_bound) & (df_train[column] <= upper_bound)\n",
    "\n",
    "# Apply the mask to filter out outliers across all columns\n",
    "df_train_filtered = df_train[mask]\n",
    "\n",
    "# Calculate the number of rows after filtering\n",
    "filtered_row_count = len(df_train_filtered)\n",
    "\n",
    "# Calculate and print the number of rows removed\n",
    "rows_removed = original_row_count - filtered_row_count\n",
    "print(f\"Rows removed: {rows_removed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into X and y to train and test the model\n",
    "X = df_train_filtered.drop(columns=['smoking','id'])\n",
    "y = df_train_filtered['smoking']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156449, 22)\n",
      "(156449,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)  # For features\n",
    "print(y.shape)  # For target labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Define a pipeline combining a standard scaler and the SVM model\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SVC())\n",
    "])\n",
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'svm__C': [0.1, 1, 10],\n",
    "    'svm__kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "# Set up the grid search with cross-validation\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5)\n",
    "\n",
    "# Fit grid search to find the best parameters\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"Best parameters found:\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was the first attempt with default parameters for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.75317993 0.75375519 0.7564078  0.75880473 0.7580939 ]\n",
      "Average score: 0.7560483099641981\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize your model\n",
    "model = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "# Perform cross-validation\n",
    "scores = cross_val_score(model, X_scaled, y, cv=5) # 5-fold cross-validation\n",
    "\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "print(\"Average score:\", scores.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After testing we decided to go with XGBoost because the performance was better in every scenario. Then we proceeded to test which features work better in XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Outliers, que fue con z-score mandar IQR y pedir que lo haga zscore\n",
    "SVM "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pda-ie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
